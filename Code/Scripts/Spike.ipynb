{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Spike.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EJpuQFGkjWU0"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH-IWF1kNGXE",
        "colab_type": "text"
      },
      "source": [
        "# Download file(.zip) from G-Drive Public Link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUX5TSG5taE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6byiFN_itHe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extracting zip file from google drive\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Data/Kiwi.zip\", 'r')\n",
        "zip_ref.extractall('/content/Dataset/')\n",
        "zip_ref.close()\n",
        "print(\"Extracted Sucessfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvvm3-91RNm7",
        "colab_type": "text"
      },
      "source": [
        "# Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXchwxkPWthK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/Dataset/WS_Dataset/'\n",
        "!ls '/content/Dataset/WS_Dataset/'\n",
        "train_dir = path + 'train'\n",
        "test_dir = path + 'test'\n",
        "val_dir = path + 'val'\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "batch_size = 50\n",
        "no_of_classes = 3\n",
        "print(\"Parameter Set Done!! \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pm2NsieSRNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, os.path\n",
        "def cal_step(dir, batch_size=batch_size):\n",
        "  id = []\n",
        "  for r,d,file in os.walk(dir):\n",
        "      id.append(file)\n",
        "  id = id[1:]\n",
        "  sum = 0\n",
        "  for i in id:\n",
        "    sum += len(i)\n",
        "  batch = int(sum/batch_size)\n",
        "  return batch \n",
        "\n",
        "print(\"Test Step {}\".format(cal_step(test_dir)))\n",
        "print(\"Train Step {}\".format(cal_step(train_dir)))\n",
        "print(\"Val Step {}\".format(cal_step(val_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMiqUsFdpZgd",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Fuctions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwn0d7tkpeA1",
        "colab_type": "text"
      },
      "source": [
        "## Run ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBcsu-5ZZ1pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from skimage import exposure,util\n",
        "import matplotlib.pyplot as plt\n",
        "Datagen_Train = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rescale=1./255,\n",
        "        fill_mode='nearest',\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        brightness_range = [0.6,1.0],\n",
        "        data_format=K.image_data_format()\n",
        "        )\n",
        "Datagen_Test = ImageDataGenerator(rescale=1./255,data_format=K.image_data_format())\n",
        "print(\"Datagen Train & Test  Created!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htDVoWfbtR68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = Datagen_Train.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        shuffle = True, \n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = Datagen_Test.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        shuffle = True,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = Datagen_Test.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfpY4gpR_H1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot \n",
        "x,y = train_generator.next()\n",
        "Col = 10\n",
        "Row = 10\n",
        "# plot first few filters\n",
        "n_filters, ix = 16, 1\n",
        "fig = pyplot.figure(figsize=(18,18))\n",
        "# plot each channel separately\n",
        "for j in range(1,30):\n",
        "  ix += 1\n",
        "  # specify subplot and turn of axis\n",
        "  ax = pyplot.subplot(Col, Row, ix)\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "  # plot filter channel in grayscale\n",
        "  pyplot.imshow(x[ix, :, :, :],cmap=\"gray\")\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30lOqX90lolZ",
        "colab_type": "text"
      },
      "source": [
        "# Model_Spike"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xKZ3PF0-lQw",
        "colab_type": "text"
      },
      "source": [
        "## Spike Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itBCi2oj-n-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Input, Concatenate,Add, BatchNormalization\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "inputs = Input(shape=(img_width,img_height,3))\n",
        "X = Conv2D(filters=16,kernel_size=(3,3),padding=\"same\", activation=\"relu\")(inputs)\n",
        "X = Conv2D(filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\")(X)\n",
        "X = MaxPooling2D(pool_size=(2,2),strides=(2,2))(X)\n",
        "X = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\")(X)\n",
        "X = MaxPooling2D(pool_size=(2,2),strides=(2,2))(X)\n",
        "X_shortcut = X\n",
        "\n",
        "#Create Towers \n",
        "tower_1 = Conv2D(64, (1,1), padding='same', activation='relu')(X)\n",
        "tower_1 = Conv2D(64, (3,3), padding='same', activation='relu')(tower_1)\n",
        "tower_2 = Conv2D(64, (1,1), padding='same', activation='relu')(X)\n",
        "tower_2 = Conv2D(64, (5,5), padding='same', activation='relu')(tower_2)\n",
        "tower_3 = Conv2D(64, (1,1), padding='same', activation='relu')(X)\n",
        "X = Concatenate(axis=3)([tower_1, tower_2, tower_3]) #Concatinate towers\n",
        "\n",
        "# ResNet Skipconnections\n",
        "X = Conv2D(filters = 64, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "X = BatchNormalization(axis = 3)(X)\n",
        "X = Activation('relu')(X)\n",
        "X = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "X = BatchNormalization(axis = 3)(X)\n",
        "X = Activation('relu')(X)\n",
        "X = Conv2D(filters = 64, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "X = BatchNormalization(axis = 3)(X)\n",
        "X = Add()([X, X_shortcut ])\n",
        "X = Activation('relu')(X)\n",
        "X = MaxPooling2D(pool_size=(2,2),strides=(2,2))(X)\n",
        "\n",
        "X = Flatten()(X)\n",
        "\n",
        "predictions = Dense(units=no_of_classes, activation=\"softmax\")(X)\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDSQkIknL4q5",
        "colab_type": "text"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyzOFIkqVWHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1393dad8-b7a4-4538-dcc7-8c0dafead5af"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "adam = optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])\n",
        "print('Compiled!')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiled!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njOyWivsVWHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "import math\n",
        "\n",
        "Ca = ModelCheckpoint(filepath = 'Model_A.hdf5', monitor='val_accuracy', mode='max', verbose = 1, save_best_only = True)\n",
        "Cl = ModelCheckpoint(filepath = 'Model_L.hdf5', monitor='val_loss', mode='min', verbose = 1, save_best_only = True)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=18)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=200, \n",
        "                    validation_data=validation_generator,  \n",
        "                    callbacks = [Cl,Ca,early_stop],\n",
        "                    validation_steps = cal_step(val_dir,batch_size),\n",
        "                    steps_per_epoch = cal_step(train_dir,batch_size)\n",
        "\t\t\t\t\t\t\t\t\t\t)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7xN1ER5gtUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save and Load Model\n",
        "model.load_weights(\"Model_L.hdf5\")\n",
        "model.save(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz9nPl-racrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"model.h5\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQPq3wFLdXgQ",
        "colab_type": "text"
      },
      "source": [
        "# Plot confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lEK6QZsVWH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import argmax\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "# model.load_weights(\"Model_L.hdf5\")\n",
        "class_labels = sorted(test_generator.class_indices.keys())\n",
        "np.set_printoptions(precision=2)\n",
        "y_prob = model.predict(test_generator, verbose=1,steps=cal_step(test_dir,batch_size)) \n",
        "predicted = np.argmax(y_prob,axis=1)\n",
        "actual = test_generator.classes\n",
        "actual = actual[:predicted.shape[0]]\n",
        "print(predicted.shape)\n",
        "print(actual.shape)\n",
        "print(actual)\n",
        "print(predicted)\n",
        "\n",
        "results = confusion_matrix(actual, predicted)\n",
        "acc = accuracy_score(actual, predicted) \n",
        "report = classification_report(actual, predicted)\n",
        "print(results) \n",
        "print ('Accuracy Score :',acc) \n",
        "print ('Report : ', report)\n",
        "result_json_file = 'confmat.txt' \n",
        "with open(result_json_file, mode='w') as f:\n",
        "    print(results,file=f)\n",
        "print(\"confmat.txt Done!!\")\n",
        "\n",
        "report_json_file = 'report.txt' \n",
        "with open(report_json_file, mode='w') as f:\n",
        "  f.write(report)\n",
        "print(\"report.txt Done!!\")\n",
        "report_df = pd.DataFrame(results) \n",
        "report_json_file = 'result.json' \n",
        "with open(report_json_file, mode='w') as f:\n",
        "    report_df.to_json(f)\n",
        "print(\"result.json Done!!\")\n",
        "\n",
        "sn.set(font_scale=1)\n",
        "plt.figure(figsize = (no_of_classes,no_of_classes))\n",
        "map = sn.heatmap(results, annot=True,annot_kws={\"size\": 20}, center=0,cmap=\"Blues\", fmt='.1f',lw=0.5, cbar=True, cbar_kws={'label': '# Images', 'orientation': 'horizontal'})\n",
        "map.set_title('Confusion matrix')\n",
        "map.set_xticklabels(class_labels, fontsize = 5)\n",
        "map.set_yticklabels(class_labels, fontsize = 5)\n",
        "figure = map.get_figure()   \n",
        "figure.savefig(\"output.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPwEtp87jdh8",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW9eLRHgVWH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate and print test accuracy\n",
        "model.load_weights(\"Model_L.hdf5\")\n",
        "score = model.evaluate(test_generator, verbose=1, steps = cal_step(test_dir,batch_size))\n",
        "print('\\n', 'Test accuracy:', score)\n",
        "pred_json_file = 'predresult.txt' \n",
        "with open(pred_json_file, mode='w') as f:\n",
        "    f.write(\"Loss: {}\\nAcc: {}\".format(score[0],score[1]))\n",
        "print(\"predresult.txt Done!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJpuQFGkjWU0",
        "colab_type": "text"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EllP5BlTVWH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finally lets visualize the loss and accuracy wrt epochs\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "fig = plt.figure(figsize=(16, 16)) \n",
        "   \n",
        " # summarize history for accuracy  \n",
        "   \n",
        "plt.subplot(211)  \n",
        "plt.plot(history.history['accuracy'])  \n",
        "plt.plot(history.history['val_accuracy'])  \n",
        "plt.title('model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "   \n",
        " # summarize history for loss  \n",
        "plt.subplot(212)  \n",
        "plt.plot(history.history['loss'])  \n",
        "plt.plot(history.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "plt.show()\n",
        "fig.savefig(\"Plot\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}